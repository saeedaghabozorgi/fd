{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline with Scikit-learn and Linear Learner\n",
    "Typically a Machine Learning (ML) process consists of few steps: data gathering with various ETL jobs, pre-processing the data, featurizing the dataset by incorporating standard techniques or prior knowledge, and finally training an ML model using an algorithm. \n",
    "In many cases, when the trained model is used for processing real time or batch prediction requests, the model receives data in a format which needs to pre-processed (e.g. featurized) before it can be passed to the algorithm. In the following notebook, we will demonstrate how you can build your ML Pipeline leveraging the Sagemaker Scikit-learn container and SageMaker Linear Learner algorithm & after the model is trained, deploy the Pipeline (Data preprocessing and Lineara Learner) as an Inference Pipeline behind a single Endpoint for real time inference and for batch inferences using Amazon SageMaker Batch Transform.\n",
    "\n",
    "We will demonstrate this using the Abalone Dataset to guess the age of Abalone with physical features. The dataset is available from [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/abalone); the aim for this task is to determine age of an Abalone (a kind of shellfish) from its physical measurements. We'll use Sagemaker's Scikit-learn container to featurize the dataset so that it can be used for training with Linear Learner.\n",
    "\n",
    "### Table of contents\n",
    "* [Preprocessing data and training the model](#training)\n",
    " * [Upload the data for training](#upload_data)\n",
    " * [Create a Scikit-learn script to train with](#create_sklearn_script)\n",
    " * [Create SageMaker Scikit Estimator](#create_sklearn_estimator)\n",
    " * [Batch transform our training data](#preprocess_train_data)\n",
    " * [Fit a LinearLearner Model with the preprocessed data](#training_model)\n",
    "* [Inference Pipeline with Scikit preprocessor and Linear Learner](#inference_pipeline)\n",
    " * [Set up the inference pipeline](#pipeline_setup)\n",
    " * [Make a request to our pipeline endpoint](#pipeline_inference_request)\n",
    " * [Delete Endpoint](#delete_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create our Sagemaker session and role, and create a S3 prefix to use for the notebook example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "bucket_name = 'demo-saeed'\n",
    "prefix = 'fraudcredit-pipeline'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data and training the model <a class=\"anchor\" id=\"training\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://demo-saeed/fraudcredit-pipeline/raw_train'}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/raw_train'.format(bucket_name, prefix))\n",
    "s3_input_train.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Scikit Estimator <a class=\"anchor\" id=\"create_sklearn_estimator\"></a>\n",
    "\n",
    "To run our Scikit-learn training script on SageMaker, we construct a `sagemaker.sklearn.estimator.sklearn` estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training. __Note__: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker.\n",
    "\n",
    "To see the code for the SKLearn Estimator, see here: https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'sklearn_fd_featurizer.py'\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    role=role,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    output_path='s3://{}/{}/output/'.format(bucket_name, prefix),\n",
    "    #code_location='s3://<path-to-code_location>', read locally from notebook\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-30 20:07:22 Starting - Starting the training job...\n",
      "2019-05-30 20:07:27 Starting - Launching requested ML instances......\n",
      "2019-05-30 20:08:33 Starting - Preparing the instances for training...\n",
      "2019-05-30 20:09:21 Downloading - Downloading input data...\n",
      "2019-05-30 20:09:35 Training - Downloading the training image..\n",
      "\u001b[31m2019-05-30 20:09:58,894 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[31m2019-05-30 20:09:58,897 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-05-30 20:09:58,908 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-05-30 20:09:59,128 sagemaker-containers INFO     Module sklearn_fd_featurizer does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-05-30 20:09:59,129 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-05-30 20:09:59,129 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-05-30 20:09:59,129 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: sklearn-fd-featurizer\n",
      "  Running setup.py bdist_wheel for sklearn-fd-featurizer: started\n",
      "  Running setup.py bdist_wheel for sklearn-fd-featurizer: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5p1vvlvm/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built sklearn-fd-featurizer\u001b[0m\n",
      "\u001b[31mInstalling collected packages: sklearn-fd-featurizer\u001b[0m\n",
      "\u001b[31mSuccessfully installed sklearn-fd-featurizer-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.1.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-05-30 20:10:00,362 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-05-30 20:10:00,379 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"module_name\": \"sklearn_fd_featurizer\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"log_level\": 20,\n",
      "    \"module_dir\": \"s3://demo-saeed/sagemaker-scikit-learn-2019-05-30-20-07-22-427/source/sourcedir.tar.gz\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2019-05-30-20-07-22-427\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"hyperparameters\": {},\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"ethwe\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sklearn_fd_featurizer.py\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"num_cpus\": 4,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=sklearn_fd_featurizer.py\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-scikit-learn-2019-05-30-20-07-22-427\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://demo-saeed/sagemaker-scikit-learn-2019-05-30-20-07-22-427/source/sourcedir.tar.gz\",\"module_name\":\"sklearn_fd_featurizer\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"sklearn_fd_featurizer.py\"}\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://demo-saeed/sagemaker-scikit-learn-2019-05-30-20-07-22-427/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_HPS={}\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=sklearn_fd_featurizer\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m sklearn_fd_featurizer\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31msaved model!\u001b[0m\n",
      "\u001b[31m2019-05-30 20:10:02,035 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-05-30 20:10:09 Uploading - Uploading generated training model\n",
      "2019-05-30 20:10:09 Completed - Training job completed\n",
      "Billable seconds: 49\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/output/sagemaker-scikit-learn-2019-05-30-20-07-22-427/output/model.tar.gz'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_preprocessor.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserCode(s3_prefix='s3://demo-saeed/sagemaker-scikit-learn-2019-05-30-20-07-22-427/source/sourcedir.tar.gz', script_name='sklearn_fd_featurizer.py')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_preprocessor.uploaded_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch transform our training data <a class=\"anchor\" id=\"preprocess_train_data\"></a>\n",
    "Now that our proprocessor is properly fitted, let's go ahead and preprocess our training data. Let's use batch transform to directly preprocess the raw data and store right back into s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn_preprocessor.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = 's3://{}/{}/preprocessed_model/'.format(bucket_name, prefix),\n",
    "    accept = 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/raw_train'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_train.config['DataSource']['S3DataSource']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/preprocessed_model/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transform job: sagemaker-scikit-learn-2019-05-30-20-10-34-916\n",
      "..........................................!\n",
      "{'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3Uri': 's3://demo-saeed/fraudcredit-pipeline/preprocessed_train/'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training input\n",
    "transformer.output_path = 's3://demo-saeed/fraudcredit-pipeline/preprocessed_train/'\n",
    "transformer.transform(s3_input_train.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv', split_type='Line')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "preprocessed_train = transformer.output_path\n",
    "s3_input_processed_train = sagemaker.session.s3_input(\n",
    "    preprocessed_train, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(s3_input_processed_train.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>-0.823091</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.189050</td>\n",
       "      <td>0.550795</td>\n",
       "      <td>0.295456</td>\n",
       "      <td>0.775733</td>\n",
       "      <td>-0.092413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115517</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.473297</td>\n",
       "      <td>1.113596</td>\n",
       "      <td>1.050489</td>\n",
       "      <td>-0.959868</td>\n",
       "      <td>-0.714505</td>\n",
       "      <td>-0.145987</td>\n",
       "      <td>0.197738</td>\n",
       "      <td>1.673615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.126314</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>-0.477632</td>\n",
       "      <td>0.593031</td>\n",
       "      <td>-0.493070</td>\n",
       "      <td>0.361389</td>\n",
       "      <td>0.285038</td>\n",
       "      <td>0.505567</td>\n",
       "      <td>-0.107495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040895</td>\n",
       "      <td>-0.241423</td>\n",
       "      <td>-0.427814</td>\n",
       "      <td>-0.127386</td>\n",
       "      <td>-0.522579</td>\n",
       "      <td>0.861587</td>\n",
       "      <td>0.616193</td>\n",
       "      <td>-0.143905</td>\n",
       "      <td>-0.047629</td>\n",
       "      <td>-0.253647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.163318</td>\n",
       "      <td>-0.374732</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.173850</td>\n",
       "      <td>-0.857184</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>-0.828474</td>\n",
       "      <td>0.093122</td>\n",
       "      <td>-0.011329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833234</td>\n",
       "      <td>0.043010</td>\n",
       "      <td>-0.041022</td>\n",
       "      <td>-0.969610</td>\n",
       "      <td>0.614542</td>\n",
       "      <td>-0.084670</td>\n",
       "      <td>-2.135301</td>\n",
       "      <td>-1.114379</td>\n",
       "      <td>-0.075676</td>\n",
       "      <td>-0.180573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.577187</td>\n",
       "      <td>0.430722</td>\n",
       "      <td>0.678611</td>\n",
       "      <td>-0.528590</td>\n",
       "      <td>1.331444</td>\n",
       "      <td>0.696371</td>\n",
       "      <td>-1.060450</td>\n",
       "      <td>0.172643</td>\n",
       "      <td>-0.004949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443527</td>\n",
       "      <td>-0.021377</td>\n",
       "      <td>-0.476229</td>\n",
       "      <td>-0.583167</td>\n",
       "      <td>-1.201115</td>\n",
       "      <td>2.358365</td>\n",
       "      <td>1.110293</td>\n",
       "      <td>0.672299</td>\n",
       "      <td>0.985151</td>\n",
       "      <td>-0.460168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.935693</td>\n",
       "      <td>0.500394</td>\n",
       "      <td>-1.116306</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>-0.735711</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.033069</td>\n",
       "      <td>0.517261</td>\n",
       "      <td>-0.104463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230172</td>\n",
       "      <td>-0.193624</td>\n",
       "      <td>-0.803500</td>\n",
       "      <td>-0.348312</td>\n",
       "      <td>1.113977</td>\n",
       "      <td>0.138441</td>\n",
       "      <td>2.137330</td>\n",
       "      <td>-0.314881</td>\n",
       "      <td>0.072460</td>\n",
       "      <td>1.884638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.185726</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>-0.931972</td>\n",
       "      <td>0.606075</td>\n",
       "      <td>-0.479313</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>1.303897</td>\n",
       "      <td>0.208337</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032159</td>\n",
       "      <td>-0.082136</td>\n",
       "      <td>0.650188</td>\n",
       "      <td>-0.055082</td>\n",
       "      <td>0.387745</td>\n",
       "      <td>-0.326944</td>\n",
       "      <td>-0.456969</td>\n",
       "      <td>-0.047581</td>\n",
       "      <td>-0.094629</td>\n",
       "      <td>0.320423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916696</td>\n",
       "      <td>0.805108</td>\n",
       "      <td>-0.483740</td>\n",
       "      <td>0.240752</td>\n",
       "      <td>-0.595583</td>\n",
       "      <td>0.481676</td>\n",
       "      <td>-0.471306</td>\n",
       "      <td>0.633701</td>\n",
       "      <td>-0.197076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218672</td>\n",
       "      <td>-0.104713</td>\n",
       "      <td>0.522820</td>\n",
       "      <td>-0.059814</td>\n",
       "      <td>0.341122</td>\n",
       "      <td>0.496978</td>\n",
       "      <td>1.718121</td>\n",
       "      <td>-0.249613</td>\n",
       "      <td>-0.246083</td>\n",
       "      <td>-0.277721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.193919</td>\n",
       "      <td>-3.385538</td>\n",
       "      <td>3.018868</td>\n",
       "      <td>-3.265232</td>\n",
       "      <td>1.266099</td>\n",
       "      <td>-3.453993</td>\n",
       "      <td>-2.141743</td>\n",
       "      <td>-2.440198</td>\n",
       "      <td>2.779663</td>\n",
       "      <td>...</td>\n",
       "      <td>1.425700</td>\n",
       "      <td>0.473639</td>\n",
       "      <td>-1.236831</td>\n",
       "      <td>-0.745679</td>\n",
       "      <td>0.361698</td>\n",
       "      <td>2.054090</td>\n",
       "      <td>-0.539148</td>\n",
       "      <td>1.575612</td>\n",
       "      <td>0.926249</td>\n",
       "      <td>0.008935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.552768</td>\n",
       "      <td>-0.967128</td>\n",
       "      <td>-0.597244</td>\n",
       "      <td>-0.074438</td>\n",
       "      <td>0.092622</td>\n",
       "      <td>0.982852</td>\n",
       "      <td>1.162178</td>\n",
       "      <td>-0.761544</td>\n",
       "      <td>-3.273056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595190</td>\n",
       "      <td>-2.438928</td>\n",
       "      <td>1.941238</td>\n",
       "      <td>1.448618</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.189926</td>\n",
       "      <td>2.549625</td>\n",
       "      <td>1.246216</td>\n",
       "      <td>0.130140</td>\n",
       "      <td>-0.406571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424926</td>\n",
       "      <td>0.432989</td>\n",
       "      <td>-0.173383</td>\n",
       "      <td>0.471375</td>\n",
       "      <td>-0.763947</td>\n",
       "      <td>0.538402</td>\n",
       "      <td>-0.400965</td>\n",
       "      <td>0.665895</td>\n",
       "      <td>-0.132075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128987</td>\n",
       "      <td>-0.056900</td>\n",
       "      <td>0.869997</td>\n",
       "      <td>-0.158206</td>\n",
       "      <td>-0.022869</td>\n",
       "      <td>-0.542452</td>\n",
       "      <td>-0.378043</td>\n",
       "      <td>0.151574</td>\n",
       "      <td>0.328365</td>\n",
       "      <td>-0.438985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.334555</td>\n",
       "      <td>0.662121</td>\n",
       "      <td>-0.685083</td>\n",
       "      <td>0.603669</td>\n",
       "      <td>-0.958557</td>\n",
       "      <td>0.158132</td>\n",
       "      <td>0.082061</td>\n",
       "      <td>0.391541</td>\n",
       "      <td>-0.090676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112511</td>\n",
       "      <td>-0.075454</td>\n",
       "      <td>0.366482</td>\n",
       "      <td>-0.139389</td>\n",
       "      <td>0.208442</td>\n",
       "      <td>0.704348</td>\n",
       "      <td>-0.515622</td>\n",
       "      <td>-0.132207</td>\n",
       "      <td>-0.048672</td>\n",
       "      <td>-0.118636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.251955</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.176937</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>-0.675958</td>\n",
       "      <td>-0.324333</td>\n",
       "      <td>-0.095893</td>\n",
       "      <td>0.450439</td>\n",
       "      <td>-0.152648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606342</td>\n",
       "      <td>-0.062130</td>\n",
       "      <td>-0.381721</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>0.567777</td>\n",
       "      <td>-1.976007</td>\n",
       "      <td>-2.480638</td>\n",
       "      <td>-0.803735</td>\n",
       "      <td>0.621307</td>\n",
       "      <td>1.010217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.013327</td>\n",
       "      <td>-0.297533</td>\n",
       "      <td>0.788188</td>\n",
       "      <td>-0.178104</td>\n",
       "      <td>1.074503</td>\n",
       "      <td>-0.640994</td>\n",
       "      <td>-0.280218</td>\n",
       "      <td>-0.765410</td>\n",
       "      <td>0.540844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609218</td>\n",
       "      <td>0.450905</td>\n",
       "      <td>0.803843</td>\n",
       "      <td>-0.132982</td>\n",
       "      <td>0.159184</td>\n",
       "      <td>0.066929</td>\n",
       "      <td>0.833058</td>\n",
       "      <td>0.563053</td>\n",
       "      <td>0.994470</td>\n",
       "      <td>-0.443298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.086891</td>\n",
       "      <td>0.316977</td>\n",
       "      <td>-0.204105</td>\n",
       "      <td>0.806508</td>\n",
       "      <td>-0.537823</td>\n",
       "      <td>0.613813</td>\n",
       "      <td>0.326593</td>\n",
       "      <td>0.754224</td>\n",
       "      <td>-0.270983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>-0.167076</td>\n",
       "      <td>0.352092</td>\n",
       "      <td>-0.402058</td>\n",
       "      <td>-0.586502</td>\n",
       "      <td>0.102336</td>\n",
       "      <td>-0.826520</td>\n",
       "      <td>-1.068258</td>\n",
       "      <td>-1.216696</td>\n",
       "      <td>-0.339326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.376546</td>\n",
       "      <td>0.804920</td>\n",
       "      <td>-0.445650</td>\n",
       "      <td>0.295863</td>\n",
       "      <td>-0.256932</td>\n",
       "      <td>0.451533</td>\n",
       "      <td>-0.289718</td>\n",
       "      <td>0.584393</td>\n",
       "      <td>-0.141321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.512836</td>\n",
       "      <td>-0.142402</td>\n",
       "      <td>0.260432</td>\n",
       "      <td>0.014454</td>\n",
       "      <td>0.070237</td>\n",
       "      <td>0.580685</td>\n",
       "      <td>-1.102446</td>\n",
       "      <td>-0.145253</td>\n",
       "      <td>-0.219781</td>\n",
       "      <td>-0.460690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428879</td>\n",
       "      <td>0.435795</td>\n",
       "      <td>-0.242289</td>\n",
       "      <td>0.608540</td>\n",
       "      <td>-0.898377</td>\n",
       "      <td>0.481781</td>\n",
       "      <td>-0.234341</td>\n",
       "      <td>0.670393</td>\n",
       "      <td>-0.112987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156571</td>\n",
       "      <td>-0.247990</td>\n",
       "      <td>-0.465342</td>\n",
       "      <td>0.046526</td>\n",
       "      <td>0.095849</td>\n",
       "      <td>-0.766379</td>\n",
       "      <td>0.248748</td>\n",
       "      <td>0.145881</td>\n",
       "      <td>0.129174</td>\n",
       "      <td>-0.455524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.495878</td>\n",
       "      <td>-0.296532</td>\n",
       "      <td>1.520962</td>\n",
       "      <td>-1.338160</td>\n",
       "      <td>2.055984</td>\n",
       "      <td>-0.136641</td>\n",
       "      <td>-1.333118</td>\n",
       "      <td>-1.009926</td>\n",
       "      <td>0.550319</td>\n",
       "      <td>...</td>\n",
       "      <td>1.220340</td>\n",
       "      <td>0.474525</td>\n",
       "      <td>-0.145222</td>\n",
       "      <td>-0.443401</td>\n",
       "      <td>-1.958804</td>\n",
       "      <td>1.732409</td>\n",
       "      <td>1.249611</td>\n",
       "      <td>1.907154</td>\n",
       "      <td>1.796038</td>\n",
       "      <td>-0.460168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>0.173253</td>\n",
       "      <td>-0.624913</td>\n",
       "      <td>0.446414</td>\n",
       "      <td>0.173167</td>\n",
       "      <td>0.123564</td>\n",
       "      <td>2.063132</td>\n",
       "      <td>1.546299</td>\n",
       "      <td>-0.469935</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.590326</td>\n",
       "      <td>-0.488997</td>\n",
       "      <td>-0.028999</td>\n",
       "      <td>0.501885</td>\n",
       "      <td>0.522536</td>\n",
       "      <td>0.174140</td>\n",
       "      <td>-0.772960</td>\n",
       "      <td>-0.629832</td>\n",
       "      <td>-3.281125</td>\n",
       "      <td>3.465581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.150514</td>\n",
       "      <td>0.290442</td>\n",
       "      <td>-0.266572</td>\n",
       "      <td>0.720734</td>\n",
       "      <td>-1.067184</td>\n",
       "      <td>0.559113</td>\n",
       "      <td>0.365718</td>\n",
       "      <td>0.627550</td>\n",
       "      <td>-0.040805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080989</td>\n",
       "      <td>-0.204243</td>\n",
       "      <td>-0.315631</td>\n",
       "      <td>-0.390696</td>\n",
       "      <td>0.286478</td>\n",
       "      <td>1.033813</td>\n",
       "      <td>1.470099</td>\n",
       "      <td>0.073104</td>\n",
       "      <td>0.133343</td>\n",
       "      <td>-0.417518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.181907</td>\n",
       "      <td>-0.500509</td>\n",
       "      <td>-0.465779</td>\n",
       "      <td>0.382336</td>\n",
       "      <td>-0.531214</td>\n",
       "      <td>0.294998</td>\n",
       "      <td>-0.403253</td>\n",
       "      <td>0.287388</td>\n",
       "      <td>0.246478</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.115212</td>\n",
       "      <td>-0.448336</td>\n",
       "      <td>-0.398122</td>\n",
       "      <td>1.492418</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>0.610355</td>\n",
       "      <td>0.243268</td>\n",
       "      <td>-0.338377</td>\n",
       "      <td>-2.060921</td>\n",
       "      <td>-0.412827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.037994</td>\n",
       "      <td>-0.027020</td>\n",
       "      <td>0.241028</td>\n",
       "      <td>0.090413</td>\n",
       "      <td>-0.292214</td>\n",
       "      <td>-0.065814</td>\n",
       "      <td>-0.437835</td>\n",
       "      <td>0.077855</td>\n",
       "      <td>-0.542607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.480739</td>\n",
       "      <td>-0.642687</td>\n",
       "      <td>0.055279</td>\n",
       "      <td>0.323124</td>\n",
       "      <td>-0.140283</td>\n",
       "      <td>0.467237</td>\n",
       "      <td>-0.412798</td>\n",
       "      <td>-1.671838</td>\n",
       "      <td>0.128877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.372495</td>\n",
       "      <td>0.804229</td>\n",
       "      <td>-0.506917</td>\n",
       "      <td>0.054419</td>\n",
       "      <td>-0.625751</td>\n",
       "      <td>1.092783</td>\n",
       "      <td>2.298103</td>\n",
       "      <td>0.481468</td>\n",
       "      <td>0.072405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356935</td>\n",
       "      <td>-0.140504</td>\n",
       "      <td>0.213079</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>1.387261</td>\n",
       "      <td>0.718121</td>\n",
       "      <td>-1.072607</td>\n",
       "      <td>-0.119813</td>\n",
       "      <td>-0.227335</td>\n",
       "      <td>-0.460168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690445</td>\n",
       "      <td>0.735688</td>\n",
       "      <td>-0.624057</td>\n",
       "      <td>0.113452</td>\n",
       "      <td>-0.548665</td>\n",
       "      <td>0.579383</td>\n",
       "      <td>-0.188526</td>\n",
       "      <td>0.711016</td>\n",
       "      <td>-0.184888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169995</td>\n",
       "      <td>0.012182</td>\n",
       "      <td>0.867847</td>\n",
       "      <td>-0.320029</td>\n",
       "      <td>1.736649</td>\n",
       "      <td>0.874064</td>\n",
       "      <td>1.323480</td>\n",
       "      <td>-0.304948</td>\n",
       "      <td>-0.194568</td>\n",
       "      <td>0.625039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875366</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>-0.846256</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>0.845510</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>0.095803</td>\n",
       "      <td>0.691410</td>\n",
       "      <td>-0.138954</td>\n",
       "      <td>...</td>\n",
       "      <td>1.117429</td>\n",
       "      <td>-0.045197</td>\n",
       "      <td>-0.536371</td>\n",
       "      <td>-0.325654</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>-0.800005</td>\n",
       "      <td>-0.587088</td>\n",
       "      <td>-0.250101</td>\n",
       "      <td>0.231320</td>\n",
       "      <td>2.962310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985572</td>\n",
       "      <td>0.817824</td>\n",
       "      <td>-0.493600</td>\n",
       "      <td>0.192150</td>\n",
       "      <td>-0.749849</td>\n",
       "      <td>0.522040</td>\n",
       "      <td>-0.314985</td>\n",
       "      <td>0.596384</td>\n",
       "      <td>-0.144591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420336</td>\n",
       "      <td>-0.094278</td>\n",
       "      <td>0.496603</td>\n",
       "      <td>-0.073802</td>\n",
       "      <td>-0.626247</td>\n",
       "      <td>0.568058</td>\n",
       "      <td>0.492466</td>\n",
       "      <td>-0.223556</td>\n",
       "      <td>-0.284629</td>\n",
       "      <td>-0.457988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0   1.0  0.005040  0.347824 -0.823091  0.214798  0.189050  0.550795  0.295456   \n",
       "1   0.0 -1.126314  0.652064 -0.477632  0.593031 -0.493070  0.361389  0.285038   \n",
       "2   1.0 -0.163318 -0.374732  0.040842  0.173850 -0.857184  0.079320 -0.828474   \n",
       "3   1.0 -1.577187  0.430722  0.678611 -0.528590  1.331444  0.696371 -1.060450   \n",
       "4   0.0 -0.935693  0.500394 -1.116306  0.499100 -0.735711 -0.025617 -0.033069   \n",
       "5   0.0  1.185726  0.719633 -0.931972  0.606075 -0.479313  0.077990  1.303897   \n",
       "6   0.0  0.916696  0.805108 -0.483740  0.240752 -0.595583  0.481676 -0.471306   \n",
       "7   1.0 -1.193919 -3.385538  3.018868 -3.265232  1.266099 -3.453993 -2.141743   \n",
       "8   1.0  1.552768 -0.967128 -0.597244 -0.074438  0.092622  0.982852  1.162178   \n",
       "9   0.0  1.424926  0.432989 -0.173383  0.471375 -0.763947  0.538402 -0.400965   \n",
       "10  0.0 -0.334555  0.662121 -0.685083  0.603669 -0.958557  0.158132  0.082061   \n",
       "11  1.0 -0.251955  0.008007  0.176937  0.071219 -0.675958 -0.324333 -0.095893   \n",
       "12  1.0 -1.013327 -0.297533  0.788188 -0.178104  1.074503 -0.640994 -0.280218   \n",
       "13  0.0 -1.086891  0.316977 -0.204105  0.806508 -0.537823  0.613813  0.326593   \n",
       "14  0.0  1.376546  0.804920 -0.445650  0.295863 -0.256932  0.451533 -0.289718   \n",
       "15  0.0  1.428879  0.435795 -0.242289  0.608540 -0.898377  0.481781 -0.234341   \n",
       "16  1.0 -1.495878 -0.296532  1.520962 -1.338160  2.055984 -0.136641 -1.333118   \n",
       "17  1.0  0.018565  0.173253 -0.624913  0.446414  0.173167  0.123564  2.063132   \n",
       "18  0.0  1.150514  0.290442 -0.266572  0.720734 -1.067184  0.559113  0.365718   \n",
       "19  0.0 -0.181907 -0.500509 -0.465779  0.382336 -0.531214  0.294998 -0.403253   \n",
       "20  1.0 -1.037994 -0.027020  0.241028  0.090413 -0.292214 -0.065814 -0.437835   \n",
       "21  0.0  1.372495  0.804229 -0.506917  0.054419 -0.625751  1.092783  2.298103   \n",
       "22  0.0  0.690445  0.735688 -0.624057  0.113452 -0.548665  0.579383 -0.188526   \n",
       "23  1.0  0.875366  0.512946 -0.846256  0.268900  0.845510  0.304228  0.095803   \n",
       "24  0.0  0.985572  0.817824 -0.493600  0.192150 -0.749849  0.522040 -0.314985   \n",
       "\n",
       "          8         9     ...           21        22        23        24  \\\n",
       "0   0.775733 -0.092413    ...     1.115517  0.018011  0.473297  1.113596   \n",
       "1   0.505567 -0.107495    ...    -0.040895 -0.241423 -0.427814 -0.127386   \n",
       "2   0.093122 -0.011329    ...    -0.833234  0.043010 -0.041022 -0.969610   \n",
       "3   0.172643 -0.004949    ...     0.443527 -0.021377 -0.476229 -0.583167   \n",
       "4   0.517261 -0.104463    ...     0.230172 -0.193624 -0.803500 -0.348312   \n",
       "5   0.208337  0.057542    ...    -0.032159 -0.082136  0.650188 -0.055082   \n",
       "6   0.633701 -0.197076    ...    -0.218672 -0.104713  0.522820 -0.059814   \n",
       "7  -2.440198  2.779663    ...     1.425700  0.473639 -1.236831 -0.745679   \n",
       "8  -0.761544 -3.273056    ...    -0.595190 -2.438928  1.941238  1.448618   \n",
       "9   0.665895 -0.132075    ...    -0.128987 -0.056900  0.869997 -0.158206   \n",
       "10  0.391541 -0.090676    ...     0.112511 -0.075454  0.366482 -0.139389   \n",
       "11  0.450439 -0.152648    ...    -0.606342 -0.062130 -0.381721  0.250962   \n",
       "12 -0.765410  0.540844    ...     0.609218  0.450905  0.803843 -0.132982   \n",
       "13  0.754224 -0.270983    ...     0.028100 -0.167076  0.352092 -0.402058   \n",
       "14  0.584393 -0.141321    ...    -0.512836 -0.142402  0.260432  0.014454   \n",
       "15  0.670393 -0.112987    ...    -0.156571 -0.247990 -0.465342  0.046526   \n",
       "16 -1.009926  0.550319    ...     1.220340  0.474525 -0.145222 -0.443401   \n",
       "17  1.546299 -0.469935    ...    -1.590326 -0.488997 -0.028999  0.501885   \n",
       "18  0.627550 -0.040805    ...    -0.080989 -0.204243 -0.315631 -0.390696   \n",
       "19  0.287388  0.246478    ...    -2.115212 -0.448336 -0.398122  1.492418   \n",
       "20  0.077855 -0.542607    ...     0.371000  0.480739 -0.642687  0.055279   \n",
       "21  0.481468  0.072405    ...    -0.356935 -0.140504  0.213079  0.030595   \n",
       "22  0.711016 -0.184888    ...     0.169995  0.012182  0.867847 -0.320029   \n",
       "23  0.691410 -0.138954    ...     1.117429 -0.045197 -0.536371 -0.325654   \n",
       "24  0.596384 -0.144591    ...    -0.420336 -0.094278  0.496603 -0.073802   \n",
       "\n",
       "          25        26        27        28        29        30  \n",
       "0   1.050489 -0.959868 -0.714505 -0.145987  0.197738  1.673615  \n",
       "1  -0.522579  0.861587  0.616193 -0.143905 -0.047629 -0.253647  \n",
       "2   0.614542 -0.084670 -2.135301 -1.114379 -0.075676 -0.180573  \n",
       "3  -1.201115  2.358365  1.110293  0.672299  0.985151 -0.460168  \n",
       "4   1.113977  0.138441  2.137330 -0.314881  0.072460  1.884638  \n",
       "5   0.387745 -0.326944 -0.456969 -0.047581 -0.094629  0.320423  \n",
       "6   0.341122  0.496978  1.718121 -0.249613 -0.246083 -0.277721  \n",
       "7   0.361698  2.054090 -0.539148  1.575612  0.926249  0.008935  \n",
       "8   0.387589  0.189926  2.549625  1.246216  0.130140 -0.406571  \n",
       "9  -0.022869 -0.542452 -0.378043  0.151574  0.328365 -0.438985  \n",
       "10  0.208442  0.704348 -0.515622 -0.132207 -0.048672 -0.118636  \n",
       "11  0.567777 -1.976007 -2.480638 -0.803735  0.621307  1.010217  \n",
       "12  0.159184  0.066929  0.833058  0.563053  0.994470 -0.443298  \n",
       "13 -0.586502  0.102336 -0.826520 -1.068258 -1.216696 -0.339326  \n",
       "14  0.070237  0.580685 -1.102446 -0.145253 -0.219781 -0.460690  \n",
       "15  0.095849 -0.766379  0.248748  0.145881  0.129174 -0.455524  \n",
       "16 -1.958804  1.732409  1.249611  1.907154  1.796038 -0.460168  \n",
       "17  0.522536  0.174140 -0.772960 -0.629832 -3.281125  3.465581  \n",
       "18  0.286478  1.033813  1.470099  0.073104  0.133343 -0.417518  \n",
       "19  0.056330  0.610355  0.243268 -0.338377 -2.060921 -0.412827  \n",
       "20  0.323124 -0.140283  0.467237 -0.412798 -1.671838  0.128877  \n",
       "21  1.387261  0.718121 -1.072607 -0.119813 -0.227335 -0.460168  \n",
       "22  1.736649  0.874064  1.323480 -0.304948 -0.194568  0.625039  \n",
       "23  0.599952 -0.800005 -0.587088 -0.250101  0.231320  2.962310  \n",
       "24 -0.626247  0.568058  0.492466 -0.223556 -0.284629 -0.457988  \n",
       "\n",
       "[25 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location = 's3://{}/{}/{}/{}'.format(bucket_name, prefix,'preprocessed_train','train.csv.out')\n",
    "df = pd.read_csv(data_location,header = None)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/raw_validation'.format(bucket_name, prefix))\n",
    "s3_input_validation.config\n",
    "# Preprocess validation input\n",
    "transformer.output_path = 's3://demo-saeed/fraudcredit-pipeline/preprocessed_validation/'\n",
    "transformer.transform(s3_input_validation.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv', split_type='Line')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "preprocessed_validation = transformer.output_path\n",
    "s3_input_processed_validation = sagemaker.session.s3_input(\n",
    "    preprocessed_validation, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(s3_input_processed_validation.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/raw_test'.format(bucket_name, prefix))\n",
    "s3_input_test.config\n",
    "# Preprocess training input\n",
    "transformer.output_path = 's3://demo-saeed/fraudcredit-pipeline/preprocessed_test/'\n",
    "transformer.transform(s3_input_test.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv', split_type='Line')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "preprocessed_test = transformer.output_path\n",
    "s3_input_processed_test = sagemaker.session.s3_input(\n",
    "    preprocessed_test, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(s3_input_processed_test.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a LinearLearner Model with the preprocessed data <a class=\"anchor\" id=\"training_model\"></a>\n",
    "Let's take the preprocessed training data and fit a LinearLearner Model. Sagemaker provides prebuilt algorithm containers that can be used with the Python SDK. The previous Scikit-learn job preprocessed the raw Titanic dataset into labeled, useable data that we can now use to fit a binary classifier Linear Learner model.\n",
    "\n",
    "For more on Linear Learner see: https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://demo-saeed/fraudcredit-pipeline/model_output\n"
     ]
    }
   ],
   "source": [
    "output_location = 's3://{}/{}/model_output'.format(bucket_name, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://demo-saeed/fraudcredit-pipeline/preprocessed_train/'}},\n",
       " 'ContentType': 'text/csv'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_processed_train.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_location = 's3://{}/{}/raw_train/train.csv'.format(bucket_name, prefix)\n",
    "\n",
    "data = pd.read_csv(data_location, header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>-0.823091</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.189050</td>\n",
       "      <td>0.550795</td>\n",
       "      <td>0.295456</td>\n",
       "      <td>0.775733</td>\n",
       "      <td>-0.092413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115517</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.473297</td>\n",
       "      <td>1.113596</td>\n",
       "      <td>1.050489</td>\n",
       "      <td>-0.959868</td>\n",
       "      <td>-0.714505</td>\n",
       "      <td>-0.145987</td>\n",
       "      <td>0.197738</td>\n",
       "      <td>1.673615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.126314</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>-0.477632</td>\n",
       "      <td>0.593031</td>\n",
       "      <td>-0.493070</td>\n",
       "      <td>0.361389</td>\n",
       "      <td>0.285038</td>\n",
       "      <td>0.505567</td>\n",
       "      <td>-0.107495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040895</td>\n",
       "      <td>-0.241423</td>\n",
       "      <td>-0.427814</td>\n",
       "      <td>-0.127386</td>\n",
       "      <td>-0.522579</td>\n",
       "      <td>0.861587</td>\n",
       "      <td>0.616193</td>\n",
       "      <td>-0.143905</td>\n",
       "      <td>-0.047629</td>\n",
       "      <td>-0.253647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.163318</td>\n",
       "      <td>-0.374732</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.173850</td>\n",
       "      <td>-0.857184</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>-0.828474</td>\n",
       "      <td>0.093122</td>\n",
       "      <td>-0.011329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833234</td>\n",
       "      <td>0.043010</td>\n",
       "      <td>-0.041022</td>\n",
       "      <td>-0.969610</td>\n",
       "      <td>0.614542</td>\n",
       "      <td>-0.084670</td>\n",
       "      <td>-2.135301</td>\n",
       "      <td>-1.114379</td>\n",
       "      <td>-0.075676</td>\n",
       "      <td>-0.180573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.577187</td>\n",
       "      <td>0.430722</td>\n",
       "      <td>0.678611</td>\n",
       "      <td>-0.528590</td>\n",
       "      <td>1.331444</td>\n",
       "      <td>0.696371</td>\n",
       "      <td>-1.060450</td>\n",
       "      <td>0.172643</td>\n",
       "      <td>-0.004949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443527</td>\n",
       "      <td>-0.021377</td>\n",
       "      <td>-0.476229</td>\n",
       "      <td>-0.583167</td>\n",
       "      <td>-1.201115</td>\n",
       "      <td>2.358365</td>\n",
       "      <td>1.110293</td>\n",
       "      <td>0.672299</td>\n",
       "      <td>0.985151</td>\n",
       "      <td>-0.460168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.935693</td>\n",
       "      <td>0.500394</td>\n",
       "      <td>-1.116306</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>-0.735711</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.033069</td>\n",
       "      <td>0.517261</td>\n",
       "      <td>-0.104463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230172</td>\n",
       "      <td>-0.193624</td>\n",
       "      <td>-0.803500</td>\n",
       "      <td>-0.348312</td>\n",
       "      <td>1.113977</td>\n",
       "      <td>0.138441</td>\n",
       "      <td>2.137330</td>\n",
       "      <td>-0.314881</td>\n",
       "      <td>0.072460</td>\n",
       "      <td>1.884638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.005040  0.347824 -0.823091  0.214798  0.189050  0.550795  0.295456   \n",
       "1  0.0 -1.126314  0.652064 -0.477632  0.593031 -0.493070  0.361389  0.285038   \n",
       "2  1.0 -0.163318 -0.374732  0.040842  0.173850 -0.857184  0.079320 -0.828474   \n",
       "3  1.0 -1.577187  0.430722  0.678611 -0.528590  1.331444  0.696371 -1.060450   \n",
       "4  0.0 -0.935693  0.500394 -1.116306  0.499100 -0.735711 -0.025617 -0.033069   \n",
       "\n",
       "         8         9     ...           21        22        23        24  \\\n",
       "0  0.775733 -0.092413    ...     1.115517  0.018011  0.473297  1.113596   \n",
       "1  0.505567 -0.107495    ...    -0.040895 -0.241423 -0.427814 -0.127386   \n",
       "2  0.093122 -0.011329    ...    -0.833234  0.043010 -0.041022 -0.969610   \n",
       "3  0.172643 -0.004949    ...     0.443527 -0.021377 -0.476229 -0.583167   \n",
       "4  0.517261 -0.104463    ...     0.230172 -0.193624 -0.803500 -0.348312   \n",
       "\n",
       "         25        26        27        28        29        30  \n",
       "0  1.050489 -0.959868 -0.714505 -0.145987  0.197738  1.673615  \n",
       "1 -0.522579  0.861587  0.616193 -0.143905 -0.047629 -0.253647  \n",
       "2  0.614542 -0.084670 -2.135301 -1.114379 -0.075676 -0.180573  \n",
       "3 -1.201115  2.358365  1.110293  0.672299  0.985151 -0.460168  \n",
       "4  1.113977  0.138441  2.137330 -0.314881  0.072460  1.884638  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_location = 's3://{}/{}/preprocessed_train/train.csv.out'.format(bucket_name, prefix)\n",
    "\n",
    "data = pd.read_csv(data_location, header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/model_output'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-30 20:16:20 Starting - Starting the training job...\n",
      "2019-05-30 20:16:21 Starting - Launching requested ML instances.........\n",
      "2019-05-30 20:17:55 Starting - Preparing the instances for training...\n",
      "2019-05-30 20:18:42 Downloading - Downloading input data\n",
      "2019-05-30 20:18:42 Training - Downloading the training image.....\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'1', u'feature_dim': u'30', u'mini_batch_size': u'200', u'predictor_type': u'binary_classifier'}\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'1', u'feature_dim': u'30', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'200', u'huber_delta': u'1.0', u'num_classes': u'1', u'predictor_type': u'binary_classifier', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 WARNING 139819483055936] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Using default worker.\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Create Store: local\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f29ed728a50>\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Scaling model computed with parameters:\n",
      " {'stdev_weight': \u001b[0m\n",
      "\u001b[31m[ 1.0065701   0.98788548  0.9921574   0.98775584  0.99475521  0.98187768\n",
      "  1.00067532  0.98665309  1.00618863  0.995812    0.98101544  0.99648821\n",
      "  0.98591071  0.99759752  0.99449891  0.98225075  0.97777689  0.97436136\n",
      "  0.9781872   0.97368616  1.00650418  1.01722765  1.01197922  1.00800776\n",
      "  1.00060785  0.99055934  1.00759733  0.99467683  1.0027895   1.01242769]\u001b[0m\n",
      "\u001b[31m<NDArray 30 @cpu(0)>, 'stdev_label': None, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[31m[ 0.01793384  0.01551692 -0.00542132  0.01203331 -0.01745084  0.01769823\n",
      "  0.00596559  0.01741447 -0.01247511  0.01853781  0.01451214 -0.01549955\n",
      "  0.01822214 -0.00170919  0.00677558  0.00837236  0.02290708  0.02032574\n",
      "  0.022494   -0.01559991  0.00896042  0.00206988 -0.01116478  0.00876353\n",
      "  0.00749041  0.00704028  0.02109066  0.00397267  0.0065569   0.00249757]\u001b[0m\n",
      "\u001b[31m<NDArray 30 @cpu(0)>}\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] nvidia-smi took: 0.0251729488373 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:26 INFO 139819483055936] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}, \"Total Records Seen\": {\"count\": 1, \"max\": 829, \"sum\": 829.0, \"min\": 829}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 629, \"sum\": 629.0, \"min\": 629}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1559247567.019869, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1559247567.019827}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7358162180582682, \"sum\": 0.7358162180582682, \"min\": 0.7358162180582682}}, \"EndTime\": 1559247567.143268, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143206}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6694723510742188, \"sum\": 0.6694723510742188, \"min\": 0.6694723510742188}}, \"EndTime\": 1559247567.143367, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143352}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6341617584228516, \"sum\": 0.6341617584228516, \"min\": 0.6341617584228516}}, \"EndTime\": 1559247567.143407, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143398}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6738132222493489, \"sum\": 0.6738132222493489, \"min\": 0.6738132222493489}}, \"EndTime\": 1559247567.143439, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143431}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5492393112182617, \"sum\": 0.5492393112182617, \"min\": 0.5492393112182617}}, \"EndTime\": 1559247567.143468, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143461}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.49144967397054035, \"sum\": 0.49144967397054035, \"min\": 0.49144967397054035}}, \"EndTime\": 1559247567.143498, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143491}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5235930379231771, \"sum\": 0.5235930379231771, \"min\": 0.5235930379231771}}, \"EndTime\": 1559247567.143533, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143525}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5376467514038086, \"sum\": 0.5376467514038086, \"min\": 0.5376467514038086}}, \"EndTime\": 1559247567.143571, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143559}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6329469807942708, \"sum\": 0.6329469807942708, \"min\": 0.6329469807942708}}, \"EndTime\": 1559247567.143645, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143607}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7603354899088541, \"sum\": 0.7603354899088541, \"min\": 0.7603354899088541}}, \"EndTime\": 1559247567.1437, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.14369}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.729942143758138, \"sum\": 0.729942143758138, \"min\": 0.729942143758138}}, \"EndTime\": 1559247567.143731, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143723}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7096214548746744, \"sum\": 0.7096214548746744, \"min\": 0.7096214548746744}}, \"EndTime\": 1559247567.143784, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143771}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5518694178263346, \"sum\": 0.5518694178263346, \"min\": 0.5518694178263346}}, \"EndTime\": 1559247567.143827, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143813}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5256063969930013, \"sum\": 0.5256063969930013, \"min\": 0.5256063969930013}}, \"EndTime\": 1559247567.143869, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.14386}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5267801666259766, \"sum\": 0.5267801666259766, \"min\": 0.5267801666259766}}, \"EndTime\": 1559247567.143898, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143891}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5262214787801107, \"sum\": 0.5262214787801107, \"min\": 0.5262214787801107}}, \"EndTime\": 1559247567.143933, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143919}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7351152038574219, \"sum\": 0.7351152038574219, \"min\": 0.7351152038574219}}, \"EndTime\": 1559247567.144009, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.143993}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6291537348429362, \"sum\": 0.6291537348429362, \"min\": 0.6291537348429362}}, \"EndTime\": 1559247567.144052, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144043}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6793043263753256, \"sum\": 0.6793043263753256, \"min\": 0.6793043263753256}}, \"EndTime\": 1559247567.144081, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144073}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6517603810628255, \"sum\": 0.6517603810628255, \"min\": 0.6517603810628255}}, \"EndTime\": 1559247567.144116, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144102}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5219476064046223, \"sum\": 0.5219476064046223, \"min\": 0.5219476064046223}}, \"EndTime\": 1559247567.144169, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144158}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5184565734863281, \"sum\": 0.5184565734863281, \"min\": 0.5184565734863281}}, \"EndTime\": 1559247567.144215, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144201}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.510593744913737, \"sum\": 0.510593744913737, \"min\": 0.510593744913737}}, \"EndTime\": 1559247567.144301, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144264}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5374135843912761, \"sum\": 0.5374135843912761, \"min\": 0.5374135843912761}}, \"EndTime\": 1559247567.144369, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144352}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6767608642578125, \"sum\": 0.6767608642578125, \"min\": 0.6767608642578125}}, \"EndTime\": 1559247567.144422, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144412}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6236993281046549, \"sum\": 0.6236993281046549, \"min\": 0.6236993281046549}}, \"EndTime\": 1559247567.144473, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144457}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8025420379638671, \"sum\": 0.8025420379638671, \"min\": 0.8025420379638671}}, \"EndTime\": 1559247567.144538, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144521}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6677706909179687, \"sum\": 0.6677706909179687, \"min\": 0.6677706909179687}}, \"EndTime\": 1559247567.144635, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144617}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7856740824381511, \"sum\": 0.7856740824381511, \"min\": 0.7856740824381511}}, \"EndTime\": 1559247567.144697, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144681}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7459137980143229, \"sum\": 0.7459137980143229, \"min\": 0.7459137980143229}}, \"EndTime\": 1559247567.144755, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144743}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.716396001180013, \"sum\": 0.716396001180013, \"min\": 0.716396001180013}}, \"EndTime\": 1559247567.144786, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144778}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7808758290608724, \"sum\": 0.7808758290608724, \"min\": 0.7808758290608724}}, \"EndTime\": 1559247567.144824, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.144811}\n",
      "\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy_objective <loss>=0.735816218058\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_cross_entropy_objective, value=0.491449673971\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 629, \"sum\": 629.0, \"min\": 629}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}, \"Total Records Seen\": {\"count\": 1, \"max\": 1458, \"sum\": 1458.0, \"min\": 1458}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 629, \"sum\": 629.0, \"min\": 629}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1559247567.148225, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1559247567.020063}\n",
      "\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #throughput_metric: host=algo-1, train throughput=4903.83150648 records/second\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 WARNING 139819483055936] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 WARNING 139819483055936] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #train_score (algo-1) : ('binary_classification_cross_entropy_objective', 0.28467886322822022)\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #train_score (algo-1) : ('binary_classification_accuracy', 0.91732909379968208)\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #train_score (algo-1) : ('binary_f_1.000', 0.9141914191419142)\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #train_score (algo-1) : ('precision', 0.9358108108108109)\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #train_score (algo-1) : ('recall', 0.8935483870967742)\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #quality_metric: host=algo-1, train binary_classification_cross_entropy_objective <loss>=0.284678863228\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.9173290938\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.914191419142\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #quality_metric: host=algo-1, train precision <score>=0.935810810811\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] #quality_metric: host=algo-1, train recall <score>=0.893548387097\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] Best model found for hyperparameters: {\"lr_scheduler_step\": 100, \"wd\": 0.0001, \"optimizer\": \"adam\", \"lr_scheduler_factor\": 0.99, \"l1\": 0.0, \"learning_rate\": 0.1, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] Saved checkpoint to \"/tmp/tmpzLy5WT/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[31m[05/30/2019 20:19:27 INFO 139819483055936] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 523.1461524963379, \"sum\": 523.1461524963379, \"min\": 523.1461524963379}, \"finalize.time\": {\"count\": 1, \"max\": 122.1010684967041, \"sum\": 122.1010684967041, \"min\": 122.1010684967041}, \"initialize.time\": {\"count\": 1, \"max\": 176.6359806060791, \"sum\": 176.6359806060791, \"min\": 176.6359806060791}, \"check_early_stopping.time\": {\"count\": 1, \"max\": 0.90789794921875, \"sum\": 0.90789794921875, \"min\": 0.90789794921875}, \"setuptime\": {\"count\": 1, \"max\": 15.951156616210938, \"sum\": 15.951156616210938, \"min\": 15.951156616210938}, \"update.time\": {\"count\": 1, \"max\": 128.00884246826172, \"sum\": 128.00884246826172, \"min\": 128.00884246826172}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1559247567.27748, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1559247566.842991}\n",
      "\u001b[0m\n",
      "\n",
      "2019-05-30 20:19:24 Training - Training image download completed. Training in progress.\n",
      "2019-05-30 20:20:08 Uploading - Uploading generated training model\n",
      "2019-05-30 20:20:08 Completed - Training job completed\n",
      "Billable seconds: 92\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m4.2xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess)\n",
    "linear.set_hyperparameters(feature_dim=30,\n",
    "                           predictor_type='binary_classifier',\n",
    "                           epochs = 1,\n",
    "                           mini_batch_size=200)\n",
    "linear.fit({'train': s3_input_processed_train,  'validation': s3_input_processed_validation, 'test': s3_input_processed_test})\n",
    "#linear.fit({'train': s3_input_processed_train})\n",
    "\n",
    "# train_max_run = 3600,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/model_output'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: No metrics called validation:binary_f_beta found\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8ce66f31a019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmetrics_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainingJobAnalytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_job_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_job_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetric_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'line'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   2675\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   3144\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3146\u001b[0;31m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3147\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "training_job_name = linear._current_job_name\n",
    "metric_name = 'validation:binary_f_beta'\n",
    "\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=training_job_name,metric_names=[metric_name]).dataframe()\n",
    "plt = metrics_dataframe.plot(kind='line', figsize=(12,5), x='timestamp', y='value', style='b.', legend=False)\n",
    "plt.set_ylabel(metric_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "#linear.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge', endpoint_name='pip-model-aws-linear-learner1', update_endpoint=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/model_output'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linear-learner-2019-05-30-20-16-20-007'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor.content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip-model-aws-linear-learner1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>-0.823091</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.189050</td>\n",
       "      <td>0.550795</td>\n",
       "      <td>0.295456</td>\n",
       "      <td>0.775733</td>\n",
       "      <td>-0.092413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115517</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.473297</td>\n",
       "      <td>1.113596</td>\n",
       "      <td>1.050489</td>\n",
       "      <td>-0.959868</td>\n",
       "      <td>-0.714505</td>\n",
       "      <td>-0.145987</td>\n",
       "      <td>0.197738</td>\n",
       "      <td>1.673615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.126314</td>\n",
       "      <td>0.652064</td>\n",
       "      <td>-0.477632</td>\n",
       "      <td>0.593031</td>\n",
       "      <td>-0.493070</td>\n",
       "      <td>0.361389</td>\n",
       "      <td>0.285038</td>\n",
       "      <td>0.505567</td>\n",
       "      <td>-0.107495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040895</td>\n",
       "      <td>-0.241423</td>\n",
       "      <td>-0.427814</td>\n",
       "      <td>-0.127386</td>\n",
       "      <td>-0.522579</td>\n",
       "      <td>0.861587</td>\n",
       "      <td>0.616193</td>\n",
       "      <td>-0.143905</td>\n",
       "      <td>-0.047629</td>\n",
       "      <td>-0.253647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.163318</td>\n",
       "      <td>-0.374732</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.173850</td>\n",
       "      <td>-0.857184</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>-0.828474</td>\n",
       "      <td>0.093122</td>\n",
       "      <td>-0.011329</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833234</td>\n",
       "      <td>0.043010</td>\n",
       "      <td>-0.041022</td>\n",
       "      <td>-0.969610</td>\n",
       "      <td>0.614542</td>\n",
       "      <td>-0.084670</td>\n",
       "      <td>-2.135301</td>\n",
       "      <td>-1.114379</td>\n",
       "      <td>-0.075676</td>\n",
       "      <td>-0.180573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.577187</td>\n",
       "      <td>0.430722</td>\n",
       "      <td>0.678611</td>\n",
       "      <td>-0.528590</td>\n",
       "      <td>1.331444</td>\n",
       "      <td>0.696371</td>\n",
       "      <td>-1.060450</td>\n",
       "      <td>0.172643</td>\n",
       "      <td>-0.004949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443527</td>\n",
       "      <td>-0.021377</td>\n",
       "      <td>-0.476229</td>\n",
       "      <td>-0.583167</td>\n",
       "      <td>-1.201115</td>\n",
       "      <td>2.358365</td>\n",
       "      <td>1.110293</td>\n",
       "      <td>0.672299</td>\n",
       "      <td>0.985151</td>\n",
       "      <td>-0.460168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.935693</td>\n",
       "      <td>0.500394</td>\n",
       "      <td>-1.116306</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>-0.735711</td>\n",
       "      <td>-0.025617</td>\n",
       "      <td>-0.033069</td>\n",
       "      <td>0.517261</td>\n",
       "      <td>-0.104463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230172</td>\n",
       "      <td>-0.193624</td>\n",
       "      <td>-0.803500</td>\n",
       "      <td>-0.348312</td>\n",
       "      <td>1.113977</td>\n",
       "      <td>0.138441</td>\n",
       "      <td>2.137330</td>\n",
       "      <td>-0.314881</td>\n",
       "      <td>0.072460</td>\n",
       "      <td>1.884638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.005040  0.347824 -0.823091  0.214798  0.189050  0.550795  0.295456   \n",
       "1  0.0 -1.126314  0.652064 -0.477632  0.593031 -0.493070  0.361389  0.285038   \n",
       "2  1.0 -0.163318 -0.374732  0.040842  0.173850 -0.857184  0.079320 -0.828474   \n",
       "3  1.0 -1.577187  0.430722  0.678611 -0.528590  1.331444  0.696371 -1.060450   \n",
       "4  0.0 -0.935693  0.500394 -1.116306  0.499100 -0.735711 -0.025617 -0.033069   \n",
       "\n",
       "         8         9     ...           21        22        23        24  \\\n",
       "0  0.775733 -0.092413    ...     1.115517  0.018011  0.473297  1.113596   \n",
       "1  0.505567 -0.107495    ...    -0.040895 -0.241423 -0.427814 -0.127386   \n",
       "2  0.093122 -0.011329    ...    -0.833234  0.043010 -0.041022 -0.969610   \n",
       "3  0.172643 -0.004949    ...     0.443527 -0.021377 -0.476229 -0.583167   \n",
       "4  0.517261 -0.104463    ...     0.230172 -0.193624 -0.803500 -0.348312   \n",
       "\n",
       "         25        26        27        28        29        30  \n",
       "0  1.050489 -0.959868 -0.714505 -0.145987  0.197738  1.673615  \n",
       "1 -0.522579  0.861587  0.616193 -0.143905 -0.047629 -0.253647  \n",
       "2  0.614542 -0.084670 -2.135301 -1.114379 -0.075676 -0.180573  \n",
       "3 -1.201115  2.358365  1.110293  0.672299  0.985151 -0.460168  \n",
       "4  1.113977  0.138441  2.137330 -0.314881  0.072460  1.884638  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location = 's3://{}/{}/{}/{}'.format(bucket_name, prefix,'preprocessed_train','train.csv.out')\n",
    "df = pd.read_csv(data_location,header = None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>-0.823091</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.18905</td>\n",
       "      <td>0.550795</td>\n",
       "      <td>0.295456</td>\n",
       "      <td>0.775733</td>\n",
       "      <td>-0.092413</td>\n",
       "      <td>0.156344</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115517</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.473297</td>\n",
       "      <td>1.113596</td>\n",
       "      <td>1.050489</td>\n",
       "      <td>-0.959868</td>\n",
       "      <td>-0.714505</td>\n",
       "      <td>-0.145987</td>\n",
       "      <td>0.197738</td>\n",
       "      <td>1.673615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         2         3         4        5         6         7   \\\n",
       "0  0.00504  0.347824 -0.823091  0.214798  0.18905  0.550795  0.295456   \n",
       "\n",
       "         8         9         10    ...           21        22        23  \\\n",
       "0  0.775733 -0.092413  0.156344    ...     1.115517  0.018011  0.473297   \n",
       "\n",
       "         24        25        26        27        28        29        30  \n",
       "0  1.113596  1.050489 -0.959868 -0.714505 -0.145987  0.197738  1.673615  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = df.iloc[0:1, 1:]\n",
    "# X_test.columns =['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "#        'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "#        'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 0.258267343044281, 'predicted_label': 1.0}]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer\n",
    "linear_predictor.deserializer = json_deserializer\n",
    "#linear_predictor.predict(X_test.iloc[0])\n",
    "\n",
    "linear_predictor.predict(X_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Inference Pipeline with Scikit preprocessor and Linear Learner <a class=\"anchor\" id=\"serial_inference\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the inference pipeline <a class=\"anchor\" id=\"pipeline_setup\"></a>\n",
    "Setting up a Machine Learning pipeline can be done with the Pipeline Model. This sets up a list of models in a single endpoint; in this example, we configure our pipeline model with the fitted Scikit-learn inference model and the fitted Linear Learner model. Deploying the model follows the same ```deploy``` pattern in the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model()\n",
    "linear_learner_model = linear.create_model()\n",
    "\n",
    "model_name = 'inference-pipeline-' + timestamp_prefix\n",
    "endpoint_name = 'inference-pipeline-ep-' + timestamp_prefix\n",
    "sm_model = PipelineModel(\n",
    "    name=model_name, \n",
    "    role=role, \n",
    "    models=[\n",
    "        scikit_learn_inferencee_model, \n",
    "        linear_learner_model])\n",
    "\n",
    "sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inference-pipeline-ep-2019-05-30-21-34-46'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_model.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a request to our pipeline endpoint <a class=\"anchor\" id=\"pipeline_inference_request\"></a>\n",
    "\n",
    "Here we just grab the first line from the test data (you'll notice that the inference python script is very particular about the ordering of the inference request data). The ```ContentType``` field configures the first container, while the ```Accept``` field configures the last container. You can also specify each container's ```Accept``` and ```ContentType``` values using environment variables.\n",
    "\n",
    "We make our request with the payload in ```'text/csv'``` format, since that is what our script currently supports. If other formats need to be supported, this would have to be added to the ```output_fn()``` method in our entry point. Note that we set the ```Accept``` to ```application/json```, since Linear Learner does not support ```text/csv``` ```Accept```. The prediction output in this case is trying to guess the number of rings the abalone specimen would have given its other physical features; the actual number of rings is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>-0.823091</td>\n",
       "      <td>0.214798</td>\n",
       "      <td>0.18905</td>\n",
       "      <td>0.550795</td>\n",
       "      <td>0.295456</td>\n",
       "      <td>0.775733</td>\n",
       "      <td>-0.092413</td>\n",
       "      <td>0.156344</td>\n",
       "      <td>...</td>\n",
       "      <td>1.115517</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.473297</td>\n",
       "      <td>1.113596</td>\n",
       "      <td>1.050489</td>\n",
       "      <td>-0.959868</td>\n",
       "      <td>-0.714505</td>\n",
       "      <td>-0.145987</td>\n",
       "      <td>0.197738</td>\n",
       "      <td>1.673615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         2         3         4        5         6         7   \\\n",
       "0  0.00504  0.347824 -0.823091  0.214798  0.18905  0.550795  0.295456   \n",
       "\n",
       "         8         9         10    ...           21        22        23  \\\n",
       "0  0.775733 -0.092413  0.156344    ...     1.115517  0.018011  0.473297   \n",
       "\n",
       "         24        25        26        27        28        29        30  \n",
       "0  1.113596  1.050489 -0.959868 -0.714505 -0.145987  0.197738  1.673615  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": [{\"score\": 0.07547429949045181, \"predicted_label\": 0.0}]}'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "payload = X_test.values\n",
    "actual_rings = 10\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "print(predictor.predict(payload))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint <a class=\"anchor\" id=\"delete_endpoint\"></a>\n",
    "Once we are finished with the endpoint, we clean up the resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "# sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
