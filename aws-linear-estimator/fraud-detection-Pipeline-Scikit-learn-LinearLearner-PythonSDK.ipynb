{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline with Scikit-learn and Linear Learner\n",
    "Typically a Machine Learning (ML) process consists of few steps: data gathering with various ETL jobs, pre-processing the data, featurizing the dataset by incorporating standard techniques or prior knowledge, and finally training an ML model using an algorithm. \n",
    "In many cases, when the trained model is used for processing real time or batch prediction requests, the model receives data in a format which needs to pre-processed (e.g. featurized) before it can be passed to the algorithm. In the following notebook, we will demonstrate how you can build your ML Pipeline leveraging the Sagemaker Scikit-learn container and SageMaker Linear Learner algorithm & after the model is trained, deploy the Pipeline (Data preprocessing and Lineara Learner) as an Inference Pipeline behind a single Endpoint for real time inference and for batch inferences using Amazon SageMaker Batch Transform.\n",
    "\n",
    "We will demonstrate this using the Abalone Dataset to guess the age of Abalone with physical features. The dataset is available from [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets/abalone); the aim for this task is to determine age of an Abalone (a kind of shellfish) from its physical measurements. We'll use Sagemaker's Scikit-learn container to featurize the dataset so that it can be used for training with Linear Learner.\n",
    "\n",
    "### Table of contents\n",
    "* [Preprocessing data and training the model](#training)\n",
    " * [Upload the data for training](#upload_data)\n",
    " * [Create a Scikit-learn script to train with](#create_sklearn_script)\n",
    " * [Create SageMaker Scikit Estimator](#create_sklearn_estimator)\n",
    " * [Batch transform our training data](#preprocess_train_data)\n",
    " * [Fit a LinearLearner Model with the preprocessed data](#training_model)\n",
    "* [Inference Pipeline with Scikit preprocessor and Linear Learner](#inference_pipeline)\n",
    " * [Set up the inference pipeline](#pipeline_setup)\n",
    " * [Make a request to our pipeline endpoint](#pipeline_inference_request)\n",
    " * [Delete Endpoint](#delete_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create our Sagemaker session and role, and create a S3 prefix to use for the notebook example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "bucket_name = 'demo-saeed'\n",
    "prefix = 'fraudcredit-pipeline'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data and training the model <a class=\"anchor\" id=\"training\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://demo-saeed/fraudcredit-pipeline/raw'}}}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/raw'.format(bucket_name, prefix))\n",
    "s3_input_train.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Scikit-learn script to train with <a class=\"anchor\" id=\"create_sklearn_script\"></a>\n",
    "To run Scikit-learn on Sagemaker `SKLearn` Estimator with a script as an entry point. The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* SM_MODEL_DIR: A string representing the path to the directory to write model artifacts to. These artifacts are uploaded to S3 for model hosting.\n",
    "* SM_OUTPUT_DIR: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing two input channels, 'train' and 'test', were used in the call to the Chainer estimator's fit() method, the following will be set, following the format SM_CHANNEL_[channel_name]:\n",
    "\n",
    "* SM_CHANNEL_TRAIN: A string representing the path to the directory containing data in the 'train' channel\n",
    "* SM_CHANNEL_TEST: Same as above, but for the 'test' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an argparse.ArgumentParser instance. For example, the script run by this notebook:\n",
    "\n",
    "```python\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from io import StringIO\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler, OneHotEncoder\n",
    "\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    content_types, encoders, env, modules, transformer, worker)\n",
    "\n",
    "# Since we get a headerless CSV file we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    'sex', # M, F, and I (infant)\n",
    "    'length', # Longest shell measurement\n",
    "    'diameter', # perpendicular to length\n",
    "    'height', # with meat in shell\n",
    "    'whole_weight', # whole abalone\n",
    "    'shucked_weight', # weight of meat\n",
    "    'viscera_weight', # gut weight (after bleeding)\n",
    "    'shell_weight'] # after being dried\n",
    "\n",
    "label_column = 'rings'\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    'sex': str,\n",
    "    'length': np.float64,\n",
    "    'diameter': np.float64,\n",
    "    'height': np.float64,\n",
    "    'whole_weight': np.float64,\n",
    "    'shucked_weight': np.float64,\n",
    "    'viscera_weight': np.float64,\n",
    "    'shell_weight': np.float64}\n",
    "\n",
    "label_column_dtype = {'rings': np.float64} # +1.5 gives the age in years\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train) ]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "    \n",
    "    raw_data = [ pd.read_csv(\n",
    "        file, \n",
    "        header=None, \n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype)) for file in input_files ]\n",
    "    concat_data = pd.concat(raw_data)\n",
    "    \n",
    "    # This section is adapted from the scikit-learn example of using preprocessing pipelines:\n",
    "    #\n",
    "    # https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n",
    "    #\n",
    "    # We will train our classifier with the following features:\n",
    "    # Numeric Features:\n",
    "    # - length:  Longest shell measurement\n",
    "    # - diameter: Diameter perpendicular to length\n",
    "    # - height:  Height with meat in shell\n",
    "    # - whole_weight: Weight of whole abalone\n",
    "    # - shucked_weight: Weight of meat\n",
    "    # - viscera_weight: Gut weight (after bleeding)\n",
    "    # - shell_weight: Weight after being dried\n",
    "    # Categorical Features:\n",
    "    # - sex: categories encoded as strings {'M', 'F', 'I'} where 'I' is Infant\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove('sex')\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_features = ['sex']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder=\"drop\")\n",
    "    \n",
    "    preprocessor.fit(concat_data)\n",
    "\n",
    "    joblib.dump(preprocessor, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "\n",
    "    print(\"saved model!\")\n",
    "    \n",
    "    \n",
    "def input_fn(input_data, content_type):\n",
    "    \"\"\"Parse input data payload\n",
    "    \n",
    "    We currently only take csv input. Since we need to process both labelled\n",
    "    and unlabelled data we first determine whether the label column is present\n",
    "    by looking at how many columns were provided.\n",
    "    \"\"\"\n",
    "    if content_type == 'text/csv':\n",
    "        # Read the raw input data as CSV.\n",
    "        df = pd.read_csv(StringIO(input_data), \n",
    "                         header=None)\n",
    "        \n",
    "        if len(df.columns) == len(feature_columns_names) + 1:\n",
    "            # This is a labelled example, includes the ring label\n",
    "            df.columns = feature_columns_names + [label_column]\n",
    "        elif len(df.columns) == len(feature_columns_names):\n",
    "            # This is an unlabelled example.\n",
    "            df.columns = feature_columns_names\n",
    "            \n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "        \n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"Format prediction output\n",
    "    \n",
    "    The default accept/content-type between containers for serial inference is JSON.\n",
    "    We also want to set the ContentType or mimetype as the same value as accept so the next\n",
    "    container can read the response payload correctly.\n",
    "    \"\"\"\n",
    "    if accept == \"application/json\":\n",
    "        instances = []\n",
    "        for row in prediction.tolist():\n",
    "            instances.append({\"features\": row})\n",
    "\n",
    "        json_output = {\"instances\": instances}\n",
    "\n",
    "        return worker.Response(json.dumps(json_output), accept, mimetype=accept)\n",
    "    elif accept == 'text/csv':\n",
    "        return worker.Response(encoders.encode(prediction, accept), accept, mimetype=accept)\n",
    "    else:\n",
    "        raise RuntimeException(\"{} accept type is not supported by this script.\".format(accept))\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Preprocess input data\n",
    "    \n",
    "    We implement this because the default predict_fn uses .predict(), but our model is a preprocessor\n",
    "    so we want to use .transform().\n",
    "\n",
    "    The output is returned in the following order:\n",
    "    \n",
    "        rest of features either one hot encoded or standardized\n",
    "    \"\"\"\n",
    "    features = model.transform(input_data)\n",
    "    \n",
    "    if label_column in input_data:\n",
    "        # Return the label (as the first column) and the set of features.\n",
    "        return np.insert(features, 0, input_data[label_column], axis=1)\n",
    "    else:\n",
    "        # Return only the set of features\n",
    "        return features\n",
    "    \n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize fitted model\n",
    "    \"\"\"\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return preprocessor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Scikit Estimator <a class=\"anchor\" id=\"create_sklearn_estimator\"></a>\n",
    "\n",
    "To run our Scikit-learn training script on SageMaker, we construct a `sagemaker.sklearn.estimator.sklearn` estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training. __Note__: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker.\n",
    "\n",
    "To see the code for the SKLearn Estimator, see here: https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'sklearn_fd_featurizer.py'\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    role=role,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    output_path='s3://{}/{}/output/'.format(bucket_name, prefix),\n",
    "    #code_location='s3://<path-to-code_location>', read locally from notebook\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 04:00:14 Starting - Starting the training job...\n",
      "2019-05-29 04:00:30 Starting - Launching requested ML instances......\n",
      "2019-05-29 04:01:39 Starting - Preparing the instances for training......\n",
      "2019-05-29 04:02:37 Downloading - Downloading input data\n",
      "2019-05-29 04:02:37 Training - Downloading the training image...\n",
      "2019-05-29 04:03:15 Uploading - Uploading generated training model\n",
      "\u001b[31m2019-05-29 04:03:03,538 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:03,540 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:03,551 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:03,850 sagemaker-containers INFO     Module sklearn_fd_featurizer does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:03,850 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:03,851 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:03,851 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: sklearn-fd-featurizer\n",
      "  Running setup.py bdist_wheel for sklearn-fd-featurizer: started\n",
      "  Running setup.py bdist_wheel for sklearn-fd-featurizer: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-v2zngj68/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built sklearn-fd-featurizer\u001b[0m\n",
      "\u001b[31mInstalling collected packages: sklearn-fd-featurizer\u001b[0m\n",
      "\u001b[31mSuccessfully installed sklearn-fd-featurizer-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.1.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:05,300 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:05,312 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"log_level\": 20,\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"module_name\": \"sklearn_fd_featurizer\",\n",
      "    \"user_entry_point\": \"sklearn_fd_featurizer.py\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"ethwe\",\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"hyperparameters\": {},\n",
      "    \"num_cpus\": 4,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2019-05-29-04-00-14-321\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"module_dir\": \"s3://demo-saeed/sagemaker-scikit-learn-2019-05-29-04-00-14-321/source/sourcedir.tar.gz\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"num_gpus\": 0,\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-scikit-learn-2019-05-29-04-00-14-321\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://demo-saeed/sagemaker-scikit-learn-2019-05-29-04-00-14-321/source/sourcedir.tar.gz\",\"module_name\":\"sklearn_fd_featurizer\",\"network_interface_name\":\"ethwe\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"sklearn_fd_featurizer.py\"}\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=sklearn_fd_featurizer.py\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_HPS={}\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=sklearn_fd_featurizer\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://demo-saeed/sagemaker-scikit-learn-2019-05-29-04-00-14-321/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[]\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m sklearn_fd_featurizer\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m['/opt/ml/input/data/train/creditcard.csv']\u001b[0m\n",
      "\u001b[31msaved model!\u001b[0m\n",
      "\u001b[31m2019-05-29 04:03:11,012 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-05-29 04:03:20 Completed - Training job completed\n",
      "Billable seconds: 58\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/output/sagemaker-scikit-learn-2019-05-29-04-00-14-321/output/model.tar.gz'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_preprocessor.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserCode(s3_prefix='s3://demo-saeed/sagemaker-scikit-learn-2019-05-29-04-00-14-321/source/sourcedir.tar.gz', script_name='sklearn_fd_featurizer.py')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_preprocessor.uploaded_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch transform our training data <a class=\"anchor\" id=\"preprocess_train_data\"></a>\n",
    "Now that our proprocessor is properly fitted, let's go ahead and preprocess our training data. Let's use batch transform to directly preprocess the raw data and store right back into s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-scikit-learn-2019-05-28-17-12-26-130\n"
     ]
    }
   ],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn_preprocessor.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = 's3://{}/{}/transformer_output/'.format(bucket_name, prefix),\n",
    "    accept = 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/raw'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_train.config['DataSource']['S3DataSource']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/transformer_output/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transform job: sagemaker-scikit-learn-2019-05-28-17-20-29-518\n",
      "...............................................!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/transformer_output/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess training input\n",
    "transformer.transform(s3_input_train.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv', split_type='Line')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "preprocessed_train = transformer.output_path\n",
    "preprocessed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a LinearLearner Model with the preprocessed data <a class=\"anchor\" id=\"training_model\"></a>\n",
    "Let's take the preprocessed training data and fit a LinearLearner Model. Sagemaker provides prebuilt algorithm containers that can be used with the Python SDK. The previous Scikit-learn job preprocessed the raw Titanic dataset into labeled, useable data that we can now use to fit a binary classifier Linear Learner model.\n",
    "\n",
    "For more on Linear Learner see: https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  0.0 -1.996583 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n",
       "1  0.0 -1.996583  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n",
       "2  0.0 -1.996562 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n",
       "3  0.0 -1.996562 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n",
       "4  0.0 -1.996541 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n",
       "\n",
       "         8         9     ...           21        22        23        24  \\\n",
       "0  0.193679  0.082637    ...     0.326118 -0.024923  0.382854 -0.176911   \n",
       "1 -0.063700  0.071253    ...    -0.089611 -0.307377 -0.880077  0.162201   \n",
       "2  0.639776  0.207373    ...     0.680975  0.337632  1.063358  1.456320   \n",
       "3  0.192071  0.316018    ...    -0.269855 -0.147443  0.007267 -0.304777   \n",
       "4  0.479302 -0.226510    ...     0.529939 -0.012839  1.100011 -0.220123   \n",
       "\n",
       "         25        26        27        28        29        30  \n",
       "0  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964  \n",
       "1 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475  \n",
       "2 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686  \n",
       "3 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534  \n",
       "4  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_location = 's3://demo-saeed/fraudcredit-pipeline/transformer_output/creditcard.csv.out'\n",
    "\n",
    "data = pd.read_csv(data_location, header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 1:]\n",
    "y = data.loc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  182261\n",
      "Number transactions Validation dataset:  45566\n",
      "Number transactions test dataset:  56957\n",
      "Total number of transactions:  284784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size = 0.2 ,random_state = 0)\n",
    "\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions Validation dataset: \", len(X_val))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_val)+len(X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://demo-saeed/fraudcredit-pipeline/model_train'}}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, X_train.values.astype('float32'), y_train.values.reshape(-1).astype('float32'))\n",
    "f.seek(0)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'model_train','linear_train.data')).upload_fileobj(f)\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/model_train'.format(bucket_name, prefix))\n",
    "s3_input_train.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://demo-saeed/fraudcredit-pipeline/model_validation'}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, X_val.values.astype('float32'), y_val.values.reshape(-1).astype('float32'))\n",
    "f.seek(0)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'model_validation','linear_val.data')).upload_fileobj(f)\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/model_validation'.format(bucket_name, prefix))\n",
    "s3_input_validation.config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
       "   'S3DataType': 'S3Prefix',\n",
       "   'S3Uri': 's3://demo-saeed/fraudcredit-pipeline/model_test'}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = 'linear_test.data'\n",
    "\n",
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, X_test.values.astype('float32'), y_test.values.reshape(-1).astype('float32'))\n",
    "f.seek(0)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'model_test',test_file)).upload_fileobj(f)\n",
    "s3_input_test = sagemaker.s3_input(s3_data='s3://{}/{}/model_test'.format(bucket_name, prefix))\n",
    "s3_input_test.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://demo-saeed/fraudcredit-pipeline/model_output\n"
     ]
    }
   ],
   "source": [
    "output_location = 's3://{}/{}/model_output'.format(bucket_name, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182261, 30)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-28 17:32:20 Starting - Starting the training job...\n",
      "2019-05-28 17:32:21 Starting - Launching requested ML instances.........\n",
      "2019-05-28 17:33:55 Starting - Preparing the instances for training...\n",
      "2019-05-28 17:34:34 Downloading - Downloading input data."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m4.2xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess)\n",
    "linear.set_hyperparameters(feature_dim=30,\n",
    "                           predictor_type='binary_classifier',\n",
    "                           epochs = 1,\n",
    "                           mini_batch_size=200)\n",
    "\n",
    "linear.fit({'train': s3_input_train,  'validation': s3_input_validation, 'test': s3_input_test})\n",
    "\n",
    "# train_max_run = 3600,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://demo-saeed/fraudcredit-pipeline/model_output'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "training_job_name = linear._current_job_name\n",
    "metric_name = 'validation:binary_f_beta'\n",
    "\n",
    "metrics_dataframe = TrainingJobAnalytics(training_job_name=training_job_name,metric_names=[metric_name]).dataframe()\n",
    "plt = metrics_dataframe.plot(kind='line', figsize=(12,5), x='timestamp', y='value', style='b.', legend=False)\n",
    "plt.set_ylabel(metric_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateEndpoint operation: Cannot create already existing endpoint \"arn:aws:sagemaker:us-east-1:079329190341:endpoint/pip-model-aws-linear-learner\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-c41a423e938c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#linear.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlinear_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.c5.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pip-model-aws-linear-learner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             tags=self.tags)\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             self.sagemaker_session.endpoint_from_production_variants(self.endpoint_name, [production_variant],\n\u001b[0;32m--> 280\u001b[0;31m                                                                      tags, kms_key)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateEndpoint operation: Cannot create already existing endpoint \"arn:aws:sagemaker:us-east-1:079329190341:endpoint/pip-model-aws-linear-learner\"."
     ]
    }
   ],
   "source": [
    "#linear.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.c5.xlarge', endpoint_name='pip-model-aws-linear-learner', update_endpoint=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/csv'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predictor.content_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pip-model-aws-linear-learner'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns =['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 0.0032706407364457846, 'predicted_label': 0.0}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer\n",
    "linear_predictor.deserializer = json_deserializer\n",
    "#linear_predictor.predict(X_test.iloc[0])\n",
    "\n",
    "linear_predictor.predict(X_test.loc[83053])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Inference Pipeline with Scikit preprocessor and Linear Learner <a class=\"anchor\" id=\"serial_inference\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the inference pipeline <a class=\"anchor\" id=\"pipeline_setup\"></a>\n",
    "Setting up a Machine Learning pipeline can be done with the Pipeline Model. This sets up a list of models in a single endpoint; in this example, we configure our pipeline model with the fitted Scikit-learn inference model and the fitted Linear Learner model. Deploying the model follows the same ```deploy``` pattern in the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model()\n",
    "linear_learner_model = linear.create_model()\n",
    "\n",
    "model_name = 'inference-pipeline-' + timestamp_prefix\n",
    "endpoint_name = 'inference-pipeline-ep-' + timestamp_prefix\n",
    "sm_model = PipelineModel(\n",
    "    name=model_name, \n",
    "    role=role, \n",
    "    models=[\n",
    "        scikit_learn_inferencee_model, \n",
    "        linear_learner_model])\n",
    "\n",
    "sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inference-pipeline-ep-2019-05-29-04-08-33'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_model.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a request to our pipeline endpoint <a class=\"anchor\" id=\"pipeline_inference_request\"></a>\n",
    "\n",
    "Here we just grab the first line from the test data (you'll notice that the inference python script is very particular about the ordering of the inference request data). The ```ContentType``` field configures the first container, while the ```Accept``` field configures the last container. You can also specify each container's ```Accept``` and ```ContentType``` values using environment variables.\n",
    "\n",
    "We make our request with the payload in ```'text/csv'``` format, since that is what our script currently supports. If other formats need to be supported, this would have to be added to the ```output_fn()``` method in our entry point. Note that we set the ```Accept``` to ```application/json```, since Linear Learner does not support ```text/csv``` ```Accept```. The prediction output in this case is trying to guess the number of rings the abalone specimen would have given its other physical features; the actual number of rings is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.24786986316588436,0.6219285089696768,-0.40766669389149396,-0.3509218261955573,-0.8233977719261477,0.19649077448261495,0.7957025664635167,-0.3106965608154121,0.1893144439369641,-1.3452420342811608,0.6716650083446972,1.3077588367812916,0.8142580498465056,1.0119520742476555,0.2651733617318809,0.3013157742844578,-1.0654016616682236,-0.4894835126703879,1.1260764727702786,-0.20233190321945185,-0.11313468325002365,-1.0829134003296332,-3.1805931958920532,0.6657326387824644,5.848977361387145,-0.21185041492735887,0.6963500086716471,-0.2664339150607643,0.15947289316968447,0.06984808807569087'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_Data = \",\".join( map( str, X_test.iloc[0] ) )\n",
    "input_Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": [{\"score\": 0.0022159225773066282, \"predicted_label\": 0.0}]}'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "payload = input_Data\n",
    "actual_rings = 10\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "print(predictor.predict(payload))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint <a class=\"anchor\" id=\"delete_endpoint\"></a>\n",
    "Once we are finished with the endpoint, we clean up the resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "# sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
